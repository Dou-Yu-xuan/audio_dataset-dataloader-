{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librispeech_reader import *\n",
    "from librispeech_to_tfrecords import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the folder with wav files\n",
    "part = 'test'\n",
    "wav_path = '/workspace/jgusak/Data/LibriSpeech_to_classify/{}'.format(part)\n",
    "\n",
    "# file name with saved tfrecords\n",
    "tfrecord_path = '{}/wavs.tfrecord'.format(wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords(wav_path, tfrecord_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Read tfrecords without defining a graph\n",
    "Create generator to iterate through tfrecords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 237 16000\n",
      "(160000,)\n"
     ]
    }
   ],
   "source": [
    "record_iterator  =  tf.python_io.tf_record_iterator(path=tfrecord_path)\n",
    "\n",
    "for string_record in record_iterator:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(string_record)\n",
    "    \n",
    "    \n",
    "    label = example.features.feature['label'].int64_list.value[0]\n",
    "    speaker = example.features.feature['speaker'].int64_list.value[0]\n",
    "    sr = example.features.feature['sr'].int64_list.value[0]\n",
    "\n",
    "    signal_string = example.features.feature['signal_raw'].bytes_list.value[0]\n",
    "    signal = np.frombuffer(signal_string, dtype = np.uint8)\n",
    "    \n",
    "    print(label, speaker, sr)\n",
    "    print(signal.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LibriSpeechDataset(tfrecord_path=tfrecord_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['label', 'signal_raw', 'speaker', 'sr'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': <tf.Tensor 'ParseSingleExample_8/ParseSingleExample:0' shape=() dtype=int64>,\n",
       " 'signal_raw': <tf.Tensor 'ParseSingleExample_8/ParseSingleExample:1' shape=() dtype=string>,\n",
       " 'speaker': <tf.Tensor 'ParseSingleExample_8/ParseSingleExample:2' shape=() dtype=int64>,\n",
       " 'sr': <tf.Tensor 'ParseSingleExample_8/ParseSingleExample:3' shape=() dtype=int64>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a batch in the following format: tf.Example protobuf parsed from tfrecord\n",
    "batch = dataset.get_example(batch_size = 10)\n",
    "print(batch.keys())\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['wav', 'sr', 'speaker', 'label'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wav': <tf.Tensor 'Reshape_9:0' shape=(10, 40000) dtype=float32>,\n",
       " 'sr': <tf.Tensor 'strided_slice_12:0' shape=(10,) dtype=int32>,\n",
       " 'speaker': <tf.Tensor 'strided_slice_13:0' shape=(10,) dtype=int32>,\n",
       " 'label': <tf.Tensor 'strided_slice_14:0' shape=(10,) dtype=int32>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get a batch in the following format: {key:tensor} \n",
    "batch = dataset.get_wavenet_batch(batch_size = 10)\n",
    "print(batch.keys())\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define graph to read tfrecords and  iterate through batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 40000) (50,)\n",
      "(50, 40000) (50,)\n",
      "(50, 40000) (50,)\n"
     ]
    }
   ],
   "source": [
    "dataset = LibriSpeechDataset(tfrecord_path=tfrecord_path)\n",
    "\n",
    "LENGTH = 40000\n",
    "batch = dataset.get_wavenet_batch(batch_size = 50, length = LENGTH) \n",
    "\n",
    "# The op for initializing the variables.\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord = coord)\n",
    "    \n",
    "    for i in range(3):\n",
    "    \n",
    "        batch_np = sess.run(batch)\n",
    "        features, labels = batch_np['wav'], batch_np['label']\n",
    "\n",
    "        print(features.shape, labels.shape)\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
